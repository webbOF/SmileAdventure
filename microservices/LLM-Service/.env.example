# Environment Variables for LLM Service
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.3
OPENAI_MAX_TOKENS=2000
OPENAI_TIMEOUT=30

# Service Configuration
SERVICE_NAME=LLM-Service
SERVICE_PORT=8004
DEBUG=false
LOG_LEVEL=INFO

# Analysis Configuration
DEFAULT_ANALYSIS_DEPTH=comprehensive
ENABLE_CACHING=true
CACHE_TTL_SECONDS=3600

# Rate Limiting
MAX_REQUESTS_PER_MINUTE=60
MAX_TOKENS_PER_MINUTE=90000

# Database (optional for caching)
DATABASE_URL=sqlite:///./llm_service.db

# External Services
GAME_SERVICE_URL=http://localhost:8002
USERS_SERVICE_URL=http://localhost:8001
REPORTS_SERVICE_URL=http://localhost:8003

# Security
API_KEY_HEADER=X-API-Key
ALLOWED_ORIGINS=*
